<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title></title><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 40px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 2; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px !important; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; }
  #write { margin-top: 0px; padding-top: 0px; border-color: transparent !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { padding-left: 32px; padding-right: 32px; padding-bottom: 0px; break-after: avoid; }
  .typora-export #write::after { height: 0px; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.html-for-mac .inline-math-svg .MathJax_SVG { vertical-align: 0.2px; }
.md-math-block .MathJax_SVG_Display { text-align: center; margin: 0px; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; overflow-y: hidden; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: var(--monospace); }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: 400; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none 0s ease 0s; }
.MathJax_SVG_Display svg { vertical-align: middle !important; margin-bottom: 0px !important; margin-top: 0px !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="mermaid"] svg, [lang="flow"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }


html { font-size: 19px; }
html, body { margin: auto; background: rgb(254, 254, 254); }
body { font-family: Vollkorn, Palatino, Times; color: rgb(51, 51, 51); line-height: 1.4; text-align: justify; }
#write { max-width: 960px; margin: 0px auto 2em; line-height: 1.53; padding-top: 40px; }
#write > h1:first-child, h1 { margin-top: 1.6em; font-weight: normal; }
h1 { font-size: 3em; }
h2 { margin-top: 2em; font-weight: normal; }
h3 { font-weight: normal; font-style: italic; margin-top: 3em; }
h1, h2, h3 { text-align: center; }
h2::after { border-bottom: 1px solid rgb(47, 47, 47); content: ""; width: 100px; display: block; margin: 0px auto; height: 1px; }
h1 + h2, h2 + h3 { margin-top: 0.83em; }
p, .mathjax-block { margin-top: 0px; }
ul { list-style: square; padding-left: 1.2em; }
ol { padding-left: 1.2em; }
blockquote { margin-left: 1em; padding-left: 1em; border-left: 1px solid rgb(221, 221, 221); }
code, pre { font-family: Consolas, Menlo, Monaco, monospace, serif; font-size: 0.9em; background: white; }
.md-fences { margin-left: 1em; padding-left: 1em; border: 1px solid rgb(221, 221, 221); padding-bottom: 8px; padding-top: 6px; margin-bottom: 1.5em; }
a { color: rgb(36, 132, 193); text-decoration: none; }
a:hover { text-decoration: underline; }
a img { border: none; }
h1 a, h1 a:hover { color: rgb(51, 51, 51); text-decoration: none; }
hr { color: rgb(221, 221, 221); height: 1px; margin: 2em 0px; border-top: 1px solid rgb(221, 221, 221); border-bottom: none; border-left: 0px; border-right: 0px; }
.ty-table-edit { background: rgb(237, 237, 237); padding-top: 4px; }
table { margin-bottom: 1.33333rem; }
table th, table td { padding: 8px; line-height: 1.33333rem; vertical-align: top; border-top: 1px solid rgb(221, 221, 221); }
table th { font-weight: bold; }
table thead th { vertical-align: bottom; }
table caption + thead tr:first-child th, table caption + thead tr:first-child td, table colgroup + thead tr:first-child th, table colgroup + thead tr:first-child td, table thead:first-child tr:first-child th, table thead:first-child tr:first-child td { border-top: 0px; }
table tbody + tbody { border-top: 2px solid rgb(221, 221, 221); }
.task-list { padding: 0px; }
.md-task-list-item { padding-left: 1.6rem; }
.md-task-list-item > input::before { content: "√"; display: inline-block; width: 1.33333rem; height: 1.6rem; vertical-align: middle; text-align: center; color: rgb(221, 221, 221); background-color: rgb(254, 254, 254); }
.md-task-list-item > input:checked::before, .md-task-list-item > input[checked]::before { color: inherit; }
.md-tag { color: inherit; font: inherit; }
#write pre.md-meta-block { min-height: 35px; padding: 0.5em 1em; }
#write pre.md-meta-block { white-space: pre; background: rgb(248, 248, 248); border-width: 0px 30px; border-top-style: initial; border-bottom-style: initial; border-top-color: initial; border-bottom-color: initial; border-image: initial; color: rgb(153, 153, 153); width: 100vw; max-width: calc(100% + 60px); margin-left: -30px; border-left-style: solid; border-left-color: rgb(248, 248, 248); border-right-style: solid; border-right-color: rgb(248, 248, 248); margin-bottom: 2em; margin-top: -1.33333rem; padding-top: 26px; padding-bottom: 10px; line-height: 1.8em; font-size: 0.76em; padding-left: 0px; }
.md-img-error.md-image > .md-meta { vertical-align: bottom; }
#write > h5.md-focus::before { top: 2px; }
.md-toc { margin-top: 40px; }
.md-toc-content { padding-bottom: 20px; }
.outline-expander::before { color: inherit; font-size: 14px; top: auto; content: ""; font-family: FontAwesome; }
.outline-expander:hover::before, .outline-item-open > .outline-item > .outline-expander::before { content: ""; }
#typora-source { font-family: Courier, monospace; color: rgb(106, 106, 106); }
.html-for-mac #typora-sidebar { box-shadow: rgba(0, 0, 0, 0.176) 0px 6px 12px; }
.cm-s-typora-default .cm-header, .cm-s-typora-default .cm-property, .CodeMirror.cm-s-typora-default div.CodeMirror-cursor { color: rgb(66, 139, 202); }
.cm-s-typora-default .cm-atom, .cm-s-typora-default .cm-number { color: rgb(119, 119, 119); }
.typora-node .file-list-item-parent-loc, .typora-node .file-list-item-time, .typora-node .file-list-item-summary { font-family: arial, sans-serif; }
.md-task-list-item > input { margin-left: -1.3em; margin-top: calc(1rem - 12px); }
.md-mathjax-midline { background: rgb(250, 250, 250); }
.md-fences .code-tooltip { bottom: -2em !important; }
.dropdown-menu .divider { border-color: rgb(229, 229, 229); }

 .typora-export li, .typora-export p, .typora-export,  .footnote-line {white-space: normal;} 
</style>
</head>
<body class='typora-export os-windows' >
<div  id='write'  class = 'is-node'><p><span>Web Service Composition as AI Planning – a Survey[</span><a href='#'><span>1</span><span>]</span></a></p><p><span>Joachim Peer</span></p><p><span>March 22, 2005</span></p><p><strong><span>Abstract</span></strong></p><p><span>This article gives an overview of AI (Artificial Intelligence) planning techniques and discusses their application to the Web service composition problem.</span>
<span> </span></p><p><strong><span>Contents</span></strong></p><p><strong><span>1 Introduction and Motivation............................................................................ 3</span></strong></p><p><strong><span>2 Scenarios.............................................................................................................. 5</span></strong></p><p><strong><span>3 Preliminaries....................................................................................................... 6</span></strong></p><p><a href='#'><span>3.1 Formalizing the planning domain..................................................................... 6</span></a></p><p><a href='#'><span>3.2 Formalizing the Initial World............................................................................ 9</span></a></p><p><a href='#'><span>3.3 Formalizing Goals............................................................................................ 11</span></a></p><p><a href='#'><span>3.4 Representing Plans.......................................................................................... 13</span></a></p><p><strong><span>4 Basic Planning Paradigms.............................................................................. 14</span></strong></p><p><a href='#'><span>4.1 State-Space based Planning............................................................................. 14</span></a></p><p><a href='#'><span>4.2 Graph Based Planning...................................................................................... 18</span></a></p><p><a href='#'><span>4.3 Partial Order Refinement Planning................................................................ 22</span></a></p><p><a href='#'><span>4.4 Planning as Satisfiability................................................................................. 26</span></a></p><p><a href='#'><span>4.4.1 Planning as Propositional Satisfiability...................................................... 27</span></a></p><p><a href='#'><span>4.4.2 Planning as Description Logic Satisfiability............................................... 28</span></a></p><p><a href='#'><span>4.4.3 Planning as Petri-Net Reachability.............................................................. 29</span></a></p><p><a href='#'><span>4.5 Planning as Logic Programming..................................................................... 30</span></a></p><p><strong><span>5 Planning with Control Knowledge................................................................ 31</span></strong></p><p><a href='#'><span>5.1 Hierarchical Task Network Planning.............................................................. 31</span></a></p><p><a href='#'><span>5.2 High-level Program Execution........................................................................ 33</span></a></p><p><a href='#'><span>5.3 Planning As Model Checking........................................................................... 36</span></a></p><p><a href='#'><span>5.4 Temporal Planning........................................................................................... 39</span></a></p><p><strong><span>6 Discussion and Outlook.................................................................................. 41</span></strong></p><p><span> </span></p><h2><a name="1-introduction-and-motivation" class="md-header-anchor"></a><span>1 Introduction and Motivation</span></h2><p><span>Web services are distributed software components that can be exposed and invoked over the internet using standard protocols. This concept was put forward by major IT companies like Microsoft, IBM and Sun as a Webcompatible solution for distributed computing, with the particularly attractive property of being an open, fully standardized and vendor neutral approach.</span></p><p><span>Web services communicate with their clients and with other Web services by sending XML based messages over the internet. The signatures of the operations a Web service offers and the message formats it supports form its </span><em><span>interface</span></em><span>. Commonly, interface description languages (IDLs) such as the Web Service Description Language WSDL (W3C, 2002) are used to describe the service interface.</span></p><p><span>WSDL allows for decoupling abstract descriptions of service types (called </span><em><span>Port Types</span></em><span>) from concrete implementations of the services. Therefore, a single Port Type description can be used for multiple services of similar type. This allows for the definition of </span><em><span>standardized</span></em><span> service interfaces, and participants with a common interest can jointly reach agreements on the semantics of those descriptions. Based on such agreements, client applications may be crafted to use the Web services, and complex processes involving several services may be composed, for instance using the BPEL4WS (IBM et al., 2002) process description language.</span></p><p><span>A problem of this approach becomes immanent when services diverge from the initial agreements. For instance, when a service changes its implementation (e.g. to refine its service offerings) its semantics and probably its syntactic interface will change. Since there is no formal machine interpretable connection defined between the semantics and the syntactic interface, human intervention is needed to decide whether the service is still compatible with the agreed semantics or not.</span></p><p><span>A way of addressing this limitation is writing down a sufficiently large part of the semantics of a service in a </span><em><span>formal machine interpretable</span></em><span> fashion, quite analogous to the syntactic interface. This reduces the dependency on external semantic agreements that are often difficult to reach, must be reached for each new service type, and must be re-evaluated after each modification of a Web service. Instead, the semantic descriptions provide software agents with a way to autonomically reason about the service’s semantics, i.e. the preconditions and consequences of its operations.</span></p><p><span>In an environment of semantically annotated services, users who need to achieve certain goals could be assisted by software agents which automatically identify and, if necessary, dynamically compose services in order to accomplish the user’s goals, which may be either explicitly stated or derived from the situation the user is in.</span></p><p><span>However, dynamic composition of services is a hard problem and it is not entirely clear which techniques serve the problem best. One family of techniques that has been proposed for this task is AI (Artifical Intelligence) planning. Planning is a complex problem which has been investigated extensively by AI research. (Russel and Norvig, 1995) characterize the problem of planning as follows : “Planning can be interpreted as a kind of problem solving, where an agent uses its beliefs about available actions and their consequences, in order to identify a solution over an abstract set of possible plans”.</span></p><p><span>Recently, several papers, e.g. (McDermott, 2002; Srivastava and Koehler, 2003; Carman et al., 2003; Sirin and Parsia, 2004), have investigated the potentials and boundaries of applying </span><em><span>AI planning techniques</span></em><span> to derive web service processes that achieve the desired goals. In this report we aim to extend this research by providing a survey of the most important planning techniques and by discussing their suitability for dynamic Web service composition.</span></p><p><span>The remainder of the article is organized as follows: in Sect. 2 we list the scenarios we gather our requirements from. In Sect. 3 we discuss the relevant conceptual frameworks of planning. We then proceed to the discussion of basic planning paradigms in Sect. 4 and knowledge oriented planning paradigms in Sect. 5. We then contrast a collection of representative planning engines against our identified core requirements and discuss the results and possible directions for future work.</span></p><h2><a name="2---scenarios" class="md-header-anchor"></a><span>2   Scenarios</span></h2><p><span>To assess the importance of the various potential requirements we are confronted with, we consider the following collection of Web service domains:</span></p><p><span>•    The </span><em><span>Web shopping</span></em><span> domain (Peer, 2004b): A collection of services that offer capabilities to browse catalogs and purchase goods. Possible goals are to find and purchase one or more products, possibly at best price.</span></p><p><span>•    The </span><em><span>document handling</span></em><span> domain (Peer, 2004b), which is similar to the Softbots domain in (Golden, 1997): The services offer functions to manipulate files, for instance to convert, compress or encrypt them. Possible goals are series of document transformations, e.g. to convert and package a collection of documents.</span></p><p><span>•    The </span><em><span>mail replication</span></em><span> domain (Vukovic and Robinson, 2004): This domain combines electronic mail-related services, i.e. SOAP interfaces to SMTP and POP servers, with services in the document handling domain (cf. above). Typical goals in this domain are the sending and receiving of messages, and the context depended adaption of the behavior of the mail system, e.g. context- and user-dependent display, involving text translation and image conversion services.</span></p><p><span>•    The </span><em><span>traveling</span></em><span> domain (McIlraith and Son, 2002): The services in this domain offer the capability to query and book air tickets and accommodation for travelers. A typical problem of this domain is to plan for a conference attendance, which often involves additional user-defined constraints to be satisfied (e.g. the date of the conference, preferences for certain hotels or airlines).</span></p><h2><a name="3-----------preliminaries" class="md-header-anchor"></a><span>3           Preliminaries</span></h2><p><span>In general, a planning problem has the following components:</span></p><p><span>•    a description of the possible actions which may be executed (a domain theory) in some formal language.</span></p><p><span>•    a description of the initial state of the world</span></p><p><span>•    a description of the desired goal</span></p><p><span>In the following sections, we present the most important approaches to define the components of a planning problem and we will contrast them with the requirements of Web service composition problems.</span></p><h3><a name="3.1---------formalizing-the-planning-domain" class="md-header-anchor"></a><span>3.1         Formalizing the planning domain</span></h3><p><span>The aim of domain formalization is to provide a </span><em><span>domain theory</span></em><span>, i.e. a formal account of the semantics of the operations that are available or relevant to the agent. These operations can represent physical operations (e.g. defined by a robot’s physical environment) but can also represent more abstract actions (e.g. withdrawing money from a bank account).</span></p><p><span>A domain theory must formally define the </span><em><span>causal laws</span></em><span> of the operations, i.e. it must allow to axiomatize relevant aspects such as the preconditions of operations and their effects to the world. Usually, domain theories follow some state-transition model, i.e. they introduce a notion of </span><em><span>state</span></em><span> (or situation), which is a snapshot that describes the world at a certain point in time and they relate actions to transitions between such states. Most approaches define a state extensionally as a set of ground atomic formulas (atoms), where atoms that may change their value over time are called </span><em><span>fluents</span></em><span> and those that do not change are called </span><em><span>state invariants</span></em><span>.</span></p><p><span>Regarding the epistemological principles domain theories are based on, we can distinguish two variants: domain theories based on classical logics and extra-logical domain theories.</span></p><p><span>Among the logical approaches is the situation calculus, which was introduced by (McCarthy, 1963) and later refined by (Levesque et al., 1998; Pirri and Reiter, 1999), who define the situation calculus as a second-order framework designed for representing dynamically changing worlds in classical first-order language. The situation calculus represents the world and its change as sequence of situations, where each situation is a term that represents a state and is obtained by executing an action[</span><a href='#'><span>2</span><span>]</span></a><span>.</span></p><p><span>Another approach for encoding operations into first order predicate logics is the </span><em><span>event calculus</span></em><span> (Kowalski and Sergot, 1989). In the event calculus, events initiate periods during which certain properties hold. A property is initiated by an event and continues to hold until some event occurs that terminates it. The events, their effects and durations are expressed in Horn logic.</span></p><p><span>Yet another approach based on logic are action theories based on modal logics, as discussed by (Giacomo and Lenzerini, 1995; Castilho et al., 1999; Giordano et al., 1998). Like the situation calculus, the modal approaches define a system of world states where the actions are modeled as transitions between those states. Modal logic approaches allow for a very natural modeling of actions as state transitions, by conceptualizing them as </span><em><span>accessibility relations</span></em><span> in Kripke structures. As we will see later in Sect. 5.3, Kripke structures are indeed practically used to represent nondeterministic domains.</span></p><p><span>Despite the advantages of these pure logic based approaches, such as the precise semantics and the ability to prove certain properties of domain theories, the AI planning community largely uses different formalisms to express planning domains. These formalisms are largely rooted in the STRIPS (Fikes and Nilsson, 1971) notation, which was used in the 1970ies to describe planning domains for a robot system called “Shakey”. STRIPS allows to define operators directly by specifying a precondition, an ADD-list and a DELETElist, all represented as conjunctions of atoms. Intuitively, the semantics of such an operator description is that an operation is only applicable if the precondition is satisfied by the current world state (represented as a database), and that after execution of the operation the atoms of the ADD-list will be added to the world state and the atoms of the DELETE-list will be removed. However, the precise logical semantics of STRIPS has been a subject of debate for long time, with different proposals put forward, e.g. (Lifschitz, 1986; Reiter, 2001).</span></p><p><span>The ADL language (Pednault, 1989; Pednault, 1994) provides support for more expressive operator descriptions and narrows the gap between the semantically ambiguous STRIPS and the declarative situation calculus: ADL allows the definition of context dependent effects, universally quantified effects (for instance needed to model the transportation of goods using a truck), negation and disjunction.</span></p><p><span>Over the time, many AI planning systems have been developed, supporting different levels of expressivity, in many cases in a middle ground between ADL and STRIPS, sometimes even beyond, e.g. to express temporal reasoning, metrics, task networks, etc. This resulted in a wide range of “ad-hoc” formats, whose semantics have often been ambiguous. To address this problem, the Planning Domain Definition Language (PDDL) (Ghallab et al., 1998) was developed to serve as a standard domain (and problem) specification language, to ease the comparison of the various systems. PDDL allows to define domains of the expressivity of ADL, including metric fluents, and defines rules for standard-compliant extensions. Successor versions of the original PDDL version are PDDL 2.1 (Fox and Long, 2003) which added a notion of time and PDDL 2.2 which adds derived predicates and timed initial literals. Several other extensions have been proposed, for instance (Bertoli et al., 2003) which extends PDDL to express nondeterminism, limited sensing and iterative conditional plans.</span></p><h3><a name="3.2---------formalizing-the-initial-world" class="md-header-anchor"></a><span>3.2         Formalizing the Initial World</span></h3><p><span>A planning agent must take the initial world state into account, because it must provide a plan that, when executed in the initial world, will lead to the specified goal.</span></p><p><span>The conceptualizations discussed in the last section not only define the conceptual models of actions, they also define the conceptual models of the initial world description a planning agent is given. In fact, the initial world is just another world state (or situation) defined by the domain theory.</span></p><p><span>The central element that constitutes a world state in practically all approaches are the atoms that are known to be true in the initial world state. Classical AI planning approaches assume that the extensional definition of the initial world state provides a </span><em><span>complete</span></em><span> description. This allows to employ the closed world assumption, which means that any fact that is not explicitly listed in the state database is false.</span></p><p><span>For real world applications, such as in robotics or in our domains of Web service computing, these simplifying assumptions are unrealistic. In fact, we are confronted with the following problems:</span></p><p><span>•    Incomplete information: the extensional definition of the initial world does not specify all knowledge relevant to the planning task. For instance, in an e-commerce application, the agent may not know which online retailer offers which products, but it needs this information to achieve its goal of </span><em><span>buying</span></em><span> a product.</span></p><p><span>•    Wrong information: some of the atoms that are defined as true may be false in reality (and vice versa). This happens when the </span><em><span>invocation and reasonable persistence (IRP)</span></em><span> assumption (McIlraith and Son, 2001) is violated, i.e. when facts are changed after the agent has acquired knowledge about those facts and when the agent wrongly believes its knowledge is accurate.</span></p><p><span>•    Fuzzy information: for each known fluent value there might exist a certain probability that it is not correct (e.g. because of fuzzy sensors). Again, this problem does not appear frequently in our domains.</span></p><p><span>The conceptual models of planners have been extended over the time to better deal with the difficulties listed above. Since the world view of an agent may divert from the reality of the world, it is useful to explicitly represent the knowledge an agent has. The agent’s knowledge can be constituted by the knowledge of atomic facts and also certain axioms and functions. Along these lines, alternatives to the widely used closed world assumption have been investigated, for instance the </span><em><span>Local Closed World Assumption</span></em><span>(LCA), which allows to represent Local Closed World (LCW) knowledge (Golden, 1997). LCW knowledge is usually organized in two databases M and L, where the database M contains a collection of all known facts and the database L contains LCW formulas that describe the contents of M, i.e. they state for which parts of the world the agent’s knowledge can be safely assumed to be complete. For instance, when an agent queries the list of all products an online retailer </span><em><span>A</span></em><span> sells, it may assume to know all products that are available from </span><em><span>A</span></em><span> (when the IRP assumption holds).</span></p><p><span>When knowledge of agents is expressed explicitly, the necessity arises to define the influence some of the domain’s operators have on the agent’s knowledge. In other words, it is useful to distinguish operators (or effects) that change the </span><em><span>world</span></em><span> from operators (or effects) that only affect the agent’s </span><em><span>knowledge</span></em><span>. The latter are called sensing operations (or sensing effects). An extension to STRIPS that accounts for incomplete knowledge and sensing actions is UWL (Etzioni et al., 1992). Similarly, SADL (Golden, 1997) adds support for incomplete information and sensing to ADL, and NPDDL (Bertoli et al., 2003) proposes similar extensions to PDDL. An other proposed extension to PDDL is Opt (McDermott, 2002), which adds knowledge effects and </span><em><span>learnable terms</span></em><span> to the PDDL framework.</span></p><p><span>A formal situation calculus based account of the incomplete knowledge of agents and sensing actions was given in (Moore, 1985), which also introduced the notion of knowledge preconditions, which are conditions the agent’s knowledge base must fulfill to successfully apply an operator.</span></p><h3><a name="3.3---------formalizing-goals" class="md-header-anchor"></a><span>3.3         Formalizing Goals</span></h3><p><span>In most classical approaches to AI planning, goals are expressed as properties that need to hold in a desired world state (the </span><em><span>goal state</span></em><span>), usually in the form of conjunctions and disjunctions of literals (positive or negative atoms) and whereby variables are treated with existential quantification.</span></p><p><span>The planner needs to identify a solution (a plan), which, when executed in the initial world state, will result in a world state that satisfies the goal. For instance a goal </span><em><span>(color Door1 Red)</span></em><span> specifies a condition that says that the fluent </span><em><span>color</span></em><span> of </span><em><span>Door1</span></em><span> must have the value </span><em><span>Red</span></em><span> after plan execution, and a goal </span><em><span>(have-door House1 ?d)</span></em><span> would require the existence of an constant </span><em><span>c</span></em><span>, that when bound to variable ?</span><em><span>d</span></em><span>, would make the formula </span><em><span>(have-door House1 ?d)</span></em><span> true.</span></p><p><span>For automated Web service composition (and many other domains) these goals specifications are not sufficient enough. Requirements listed in the literature are:</span></p><p><span>•    Need for temporal structures: Certain complex goals can not be expressed simply as properties of a final state. For instance, the planning of a round-trip from Vienna to Zurich and back can not be expressed as a condition on the goal state because the goal state would equal the initial state (i.e. the agent being in Vienna[</span><a href='#'><span>3</span><span>]</span></a><span>). Therefore, certain structures need to be added to split the planning goal into several distinct, consecutive phases. In some cases, a valid plan may even have to include looping and branching, as noted by (Srivastava and Koehler, 2003).</span></p><p><span>•    Strategies for dealing with nondeterminism, i.e. how to behave if the execution of an operation does not achieve the expected or desired result (e.g. by defining BPEL-like </span><em><span>compensation actions</span></em><span>).</span></p><p><span>•    Safety properties: not all </span><em><span>possible</span></em><span> solutions to achieve a goal are </span><em><span>desired</span></em><span> ones. For instance, there may be certain fluents whose values should not or only moderately be changed (e.g. the credit-card balance); these protected fluents are sometimes called </span><em><span>maintenance goals</span></em><span> or </span><em><span>resource constraints</span></em><span>. Further, in many domains there are certain situations an agent may stumble into, which need to be avoided altogether, and constraints on the goal can help to evade them.</span></p><p><span>•    Distinction between </span><em><span>information goals</span></em><span> and </span><em><span>achievement goals</span></em><span>: Many problems require such a distinction because information goals should be achieved exclusively by </span><em><span>sensing actions</span></em><span>. As an example, a goal to find out the current color of an item may only use operations that do </span><em><span>not</span></em><span> actively affect its color; we would not want the agent to use an operation that sets the color to some new value and then reports that newly assigned color (Golden, 1997). Instead, the value should be gathered through a </span><em><span>sensing operation</span></em><span>.</span></p><p><span>•    Preferences of users over possible solutions (e.g. preferring air travel over traveling by train, payment via credit card over e-cash) and other user-provided constraints on the solution (e.g. buying airline ticket only if driving would take longer than 3 hours) (McIlraith and Son, 2001)</span></p><p><span>Since these difficulties are relevant to many real world planning domains, not only to Web service composition, there exist several approaches to address these problems, which will be discussed in Sect. 5.</span></p><h3><a name="3.4---------representing-plans" class="md-header-anchor"></a><span>3.4         Representing Plans</span></h3><p><span>The classical view of a plan as a solution to a planning problem is a </span><em><span>sequence of operator instances</span></em><span>, which, when executed leads to a state that satisfies the given goal. Given the discussion of goals in the last section, especially the problem of nondeterminism, it is not surprising that this classical view of plans is not always sufficient to capture the solutions to complex planning problems.</span></p><p><span>The required complexity of a plan does not only depend on the domain and goal complexity, it also depends on the execution model foreseen for the plan: if an operation does not yield the desired result, will the agent have the opportunity to re-generate the plan (as in replanning/reactive planning architectures, e.g. (Firby, 1987)), or will the agent have to rely on the predefined plan? In the latter case, a </span><em><span>conditional</span></em><span> plan is required that deals with the nondeterminism and incomplete information by constructing a plan that accounts for the possible contingencies that could arise. At runtime, the agent has to determine the situation it is in and then chose the appropriate plan branch that is prepared for that situation. Planners that adopt that strategy are also called contingency planners.</span></p><p><span>Beside contingency planners, there exist several other extensions to plans as simple sequences. As we will discuss later in Sect. 4.3, partial order planners allow for plans whose actions are partially ordered, i.e. some of the actions can be executed in parallel rather than sequentially, which often increases the efficiency of the system. Even more feature-rich plans can be created using the planning as model-checking (MC) approach described in Sect. 5.3, where the planner synthesizes plans that may contain loops and branches.</span></p><h2><a name="4-----------basic-planning-paradigms" class="md-header-anchor"></a><span>4           Basic Planning Paradigms</span></h2><p><span>In the following we will give an overview of the basic planning paradigms and some representative implementations of these concepts.</span></p><h3><a name="4.1---------state-space-based-planning" class="md-header-anchor"></a><span>4.1         State-Space based Planning</span></h3><p><span>A state space consists of a finite set of states </span><em><span>S</span></em><span>, a finite set of actions </span><em><span>A</span></em><span>, a state transition function </span><em><span>f</span></em><span> that describes how actions map one state into another, and a cost function </span><em><span>c</span></em><span>(</span><em><span>a,s</span></em><span>) </span><em><span>&gt;</span></em><span> 0 that measures the cost of performing action </span><em><span>a</span></em><span> in state </span><em><span>s</span></em><span> (Fikes and Nilsson, 1971). A state space extended with a given initial state </span><em><span>s</span></em><span>0 and a set </span><em><span>SG</span></em><span> of goals is also called a </span><em><span>state model</span></em><span> (Bonet and Geffner, 2001b).</span></p><p><span>State based planners aim to solve a planning problem by searching for useful operator instantiations that achieve the desired state. Depending on the starting point of the search, we distinguish forward state search (also called progression) and backward state search (also called regression): A progressive state based planner starts with the initial state and searches action instances that bring the planner closer to the goal. A regression planner starts with a state satisfying the goal and searches for action instances that bring the planner closer to the initial state.</span></p><p><span>In both cases, the goal is to find a sequence of actions that, when applied beginning in the initial state, will lead to the goal state. More formally, a solution of a state model is a sequence of actions </span><em><span>a</span></em><span>0</span><em><span>,a</span></em><span>1</span><em><span>,...,an</span></em><span> that generates a state trajectory </span><em><span>s</span></em><span>0</span><em><span>,s</span></em><span>1 = </span><em><span>f</span></em><span>(</span><em><span>s</span></em><span>0)</span><em><span>,...,sn</span></em><span>+1 = </span><em><span>f</span></em><span>(</span><em><span>an,sn</span></em><span>) such that each action </span><em><span>ai</span></em><span> is applicable in </span><em><span>si</span></em><span> and </span><em><span>sn</span></em><span>+1 is a goal state, i.e., </span><em><span>ai</span></em><span> ∈ </span><em><span>A</span></em><span>(</span><em><span>si</span></em><span>) and </span><em><span>sn</span></em><span>+1 ∈ </span><em><span>G</span></em><span> (Bonet and Geffner, 2001b).</span></p><p><span>In principal, any search algorithm can be used to perform state based search, and the discipline of means-end-analysis has a long tradition with roots in the 1950s since GPS (Newell and Simon, 1963). However, the usually vast number of different branches of actions a planner has to chose from calls for methods that reduce the search space or help discriminating fruitful vs. useless branches of the search tree. An early attempt for reducing the search space was the STRIPS algorithm. It uses backward search, i.e. it starts with the goal, searches an action that achieves the goal or one of its subgoals and then goes on to search actions that achieve the precondition of the actions, and so forth. STRIPS enhances this search by only considering the preconditions of the last operator added to the plan and by committing to operators whose preconditions are satisfied by the current state. This reduces the plan space significantly, but it makes STRIPS incomplete, i.e. there is no guarantee that a solution for a problem will be found even if there exists one.</span></p><p><span>A different way of dealing with the vastness of the plan space is to employ </span><em><span>heuristic functions</span></em><span> which estimate the usefulness of the alternative actions a planner can chose from, thus </span><em><span>guiding</span></em><span> the planner to chose fruitful search paths and ignore branches that will lead to dead ends or solutions of low quality. Truly automatic domain independent planners have no other choice than gathering these heuristics from the domain and the problem descriptions they are confronted with, in contrast to specialized algorithms, e.g. the algorithm solving the 8-puzzle discussed in AI textbooks like (Nilsson, 1980).</span></p><p><span>A planner adopting such a domain-independent heuristic is UNPOP (McDermott, 1996), which employs a regression-match graph. The construction of this graph starts with the goal, which is matched to the current situation, yielding a set of literals to be achieved. In the next level of the graph, actions are considered that achieve some of those subgoals, which yields another set of subgoals, needed to carry out those actions. Those subgoals are added to the next level of the graph and the process repeats. To enhance the graph traversal, the notion of </span><em><span>estimated effort</span></em><span> is used, i.e. an estimate of how many actions it will take to achieve the main goal, whereby the effort of a goal that is already given in the current situation is 0 and the effort of a goal that can not be achieved by any operator in the domain is ∞. When traversing the regression graph, UNPOP chooses branches first whose effort estimations seem favorable, which leads to an improvement in planning speed compared to “blind” unguided searches.</span></p><p><span>In related work, the forward planner HSP (Heuristic search planner) was presented, which is based on the </span><em><span>additive heuristic hadd</span></em><span>. This heuristic defines the cost of a set </span><em><span>C</span></em><span> of atoms as the sum of the cost of the elements of </span><em><span>C</span></em><span>. This assumes that subgoals are independent of each other, which is not always true because some goals can become less (or even more) difficult once other goals are fulfilled. The HSP system uses </span><em><span>hadd</span></em><span> to guide a </span><em><span>hill-climbing search</span></em><span> from the initial state to the goal. At each step, one of the best child nodes (i.e. nodes whose </span><em><span>hadd</span></em><span> value is minimal) is selected for expansion and the same process is repeated until the goal is reached. The costs are calculated as </span><em><span>estimations</span></em><span>, which are extracted from a relaxed planning problem </span><em><span>P</span></em><span> 0, where the negative effects of operators are ignored. The estimations are generated by iteratively applying the positive effects of a number of operations whose preconditions are applicable in the current state (negative effects are ignored) and by tracking for each atom that is achieved in that process after how many steps it was achieved (Bonet and Geffner, 1998). Empirical data shows that the idea of using a relaxed problem to harvest heuristic estimation as well as the assumption of goal independence yields preferable results, as documented in the results of the international planning competition IPC1998 (McDermott, 2000; Bonet and Geffner, 2001b).</span></p><p><span>In successive work, the planner HSP2 (Bonet and Geffner, 2001a) was developed, which employs the same heuristic function </span><em><span>hadd</span></em><span>, but uses </span><em><span>bestfirst search</span></em><span> (Pearl, 1985) instead of hill-climbing. The best-first search weighs nodes by an evaluation function </span><em><span>f</span></em><span>(</span><em><span>n</span></em><span>) = </span><em><span>g</span></em><span>(</span><em><span>n</span></em><span>) + </span><em><span>W</span></em><span> ∗ </span><em><span>h</span></em><span>(</span><em><span>n</span></em><span>), where </span><em><span>g</span></em><span>(</span><em><span>n</span></em><span>) is the accumulated cost, </span><em><span>h</span></em><span>(</span><em><span>n</span></em><span>) the estimated cost of the goal, and </span><em><span>W</span></em><span> is a constant. Higher values of </span><em><span>W</span></em><span> are associated with faster plan search, but also with lower plan quality (Korf, 1993). HSP2 evaluates the </span><em><span>hadd</span></em><span> heuristic from the scratch in every new state generated in HSP.</span></p><p><span>The re-generation of </span><em><span>hadd</span></em><span> is an obvious performance issue, which is a bottle neck of the HSP planners as well as related planners like UNPOP. An attempt to address this problem is HSPr (Bonet and Geffner, 1999), a variant of HSP which uses backward search from the goal rather than forward search from the initial state. The estimates are computed only once from the initial state, and the heuristic function </span><em><span>hadd</span></em><span>(</span><em><span>s</span></em><span>) is always calculated as sum of costs to achieve goals from the initial state (Bonet and Geffner, 1999). This combination of forward propagation to derive estimations and the backward search for plans is reminiscent of Graphplan (Blum and Furst, 1995), which is discussed in Sect. 4.2. While HSPr turned out to substantially improve performance in some domains, the new algorithm is inferior to HSP in others (Bonet and Geffner, 1999).</span></p><p><span>Planning as heuristic search was further advanced by the Fast Forward (FF) planner (Hoffmann, 2001), which was among the winners of the ICP2000 competition, outperforming HSP2 and others. Like HSP, FF relies on forward search in the state space, guided by a heuristic that estimates goal distances using a relaxed problem. However, FF uses a more sophisticated method of extracting heuristic values, based on a Graphplan-style algorithm (cf. Sect. 4.2). The number of actions in the relaxed solution is used as a goal distance estimate; among the advantages of Graphplan-like solution extraction is that it takes positive interactions between facts into account. The estimates are used to guide a novel kind of local search strategy, called </span><em><span>enforced hill-climbing</span></em><span>. In contrast to HSP, which randomly chooses the best successor to each intermediate state, FF evaluates all of a state’s successors (and, if necessary, the successors of the successors etc.), looking for a state with better heuristic value than the current state. In short, at each search iteration a breadth first search for a state with strictly better evaluation is performed. This strategy allows the planner to escape plateaus and local minima. A third advantageous feature of FF is its concept of </span><em><span>helpful actions</span></em><span>, i.e. it uses the information from the planning graph to identify at each state those actions that appear most useful in terms of the effects they achieve and it prefers those actions over the operators that seem superfluous (Hoffmann, 2001; Hoffmann and Nebel, 2001).</span></p><p><span>An extension to FF, called Metric-FF, was presented in (Hoffmann, 2003; Hoffmann, 2002); it handles numerical variables, constraints and effects as captured in PDDL 2.1 level 2. Metric-FF supports numerical state variables which can be used in numerical constraints in preconditions (e.g. </span><em><span>cash &gt;</span></em><span> 100) and in arithmetic operations in effects (e.g. </span><em><span>cash</span></em><span>− = 10).</span></p><p><span>While the heuristics using a relaxed planning graph has had remarkable success in recent years, in some domains the FF and HSP families of planners perform poorly, because their relaxation method of ignoring negative effects loses too much vital information. A recent heuristic search planner which addresses this problem is Fast Downward (Helmert and Richter, 2004). In contrast to the previous planners like HSP and FF, it does not use a relaxed planning graph but it uses Causal Graph (CG) data structures (Helmert, 2004) instead.</span></p><h3><a name="4.2---------graph-based-planning" class="md-header-anchor"></a><span>4.2         Graph Based Planning</span></h3><p><span>Several planners discussed so far utilize graph structures for the extraction of heuristics. In this section, we will discuss the graph planning framework introduced in (Blum and Furst, 1995), which formalizes the construction, annotation and analysis of a compact structure called Planning Graph. Despite some similarity, Planning Graphs are not space graphs such as those used in UNPOP. In fact, unlike the state-space graph, in which a plan is a path through the graph, in a Planning Graph, a plan is a </span><em><span>flow</span></em><span> in the network flow sense (Blum and Furst, 1997).</span></p><p><span>A Planning Graph is a directed leveled graph. It consists of two types of nodes, namely </span><em><span>action nodes</span></em><span> and </span><em><span>proposition nodes</span></em><span>. These nodes are arranged in alternating </span><em><span>levels</span></em><span> consisting of proposition nodes followed by layers of action nodes, and so forth. Each level is associated with a time step. The first level of a Planning Graph is a proposition level which consists of one node for each proposition of the initial situation. The second level is an action level which contains all actions whose preconditions are satisfied by the proposition nodes of the first level. The third level is again a proposition level, containing the proposition nodes from the first level and proposition nodes that represent the effects of the actions of the preceding action layer. The construction of the Planning Graph stops when two consecutive propositional layers are identical; it has been shown that this always occurs, guaranteeing the termination of the process. The complexity of creating a Planning Graph is low-order polynomial in the number of actions and propositions (Blum and Furst, 1997).</span></p><p><span>All actions at some level </span><em><span>i</span></em><span> are connected to the preconditions at level </span><em><span>i</span></em><span>−1 and its effects at level </span><em><span>i</span></em><span>+1, introducing or negating proposition in </span><em><span>i</span></em><span>+1. For literals that persist from layers </span><em><span>i</span></em><span>−1 to </span><em><span>i</span></em><span>+1 and are not connected to action nodes, persistence action nodes are added. Further, (Blum and Furst, 1995) defines mutual exclusions (“mutex”) relations for actions and literals. The possible mutex relations between actions are </span><em><span>inconsistent effects</span></em><span>, where one action negates an effect of the other, </span><em><span>inference</span></em><span>, where one of the effects of one actions is the negation of a precondition of the other and </span><em><span>competing needs</span></em><span>, where one of the preconditions of one action is mutually exclusive with a precondition of the other. A mutual relation holds between two propositions on the same level if one is the negation of the other or if each possible pair of actions that could achieve the two propositions is mutually exclusive (Russel and Norvig, 2002).</span></p><p><span>The information captured in such a Planning Graph, especially the exclusion relations propagate a variety of intuitively useful facts about the problem. This information can be used by planners to guide their search. The first planner using this technique was Graphplan, which was introduced in (Blum and Furst, 1995). The Graphplan algorithm operates in two main steps which alternate within a loop: </span><em><span>graph expansion</span></em><span> and </span><em><span>solution extraction</span></em><span>. Graph expansion grows the Planning Graph as sketched above, until a propositional level is reached where all goal propositions are present with no mutex links between any pair of them. This is a necessary (but insufficient) condition for plan existence. To look for potential plans, the solution extraction phase is then started. The Graphplan algorithm uses a backward-chaining strategy, using a level-by-level approach in order to make best use of the mutual exclusion constraints (Blum and Furst, 1997). Given a set of goals at a time (level) </span><em><span>t</span></em><span>, Graphplan aims to determine a set of actions at time </span><em><span>t</span></em><span>−1 which have these goals as effects. At each step, only actions that are not mutually exclusive with existing actions in the plan are considered. On failure, Graphplan tracks back and tries different action sets. If no plan is found and the Planning Graph is not leveled off yet, then Graphplan resumes graph expansion until another promising propositional layer is reached. The solution extraction can be formulated as a constraint solving problem[</span><a href='#'><span>4</span><span>]</span></a><span> (Do and Kambhampati, 2001) or as a search problem (Russel and Norvig, 2002).</span></p><p><span>Graphplan’s advantages are besides its good performance its theoretical properties such as soundness, completeness, generation of shortest plans and termination on unsolvable problems. However, the original Graphplan algorithm has some limitations: first, its representation language is restricted to pure STRIPS operators, no conditional or universally quantified effects are allowed; and second, the performance can decrease drastically if too much irrelevant information is contained in the specification of a planning task (Nebel et al., 1997).</span></p><p><span>In (Koehler et al., 1997), an early version of the Ipp planner is presented, which extends Graphplan to handling conditional and universally quantified effects. The authors show that this extension comes with negligible computational overhead and competes well with other planners that support ADL subsets (e.g. UCPOP and Prodigy). In additional work, the RIFO (Removing Irrelevant Operators and Initial Facts from Planning Problems) strategy (Koehler et al., 1997) was added to Ipp, addressing Graphplan’s problem with irrelevant information. Further, a Goal Agenda Manager (GAM) to order sets of subgoals and incrementally plan for subproblems (Koehler and Hoffmann, 2000) has been added to Ipp, and more recently to the FF planner.</span></p><p><span>Another planner based on Graphplan that has evolved over time is Stan (Long and Fox, 1999). It improves Graphplan in several ways. First, Stan performs a number of preprocessing analyses, or STate ANalyses, on the planning domain before planning, using the Type Inference Module (TIM) described in (Fox and Long, 1998). Further, Stan uses an efficient internal representation of preconditions and effects (as bit vectors), which allows for resource-efficient representations of the planning graph (called </span><em><span>spike</span></em><span>) and allows to carry out the mutex-checks between actions and facts using efficient bit manipulating operations[</span><a href='#'><span>5</span><span>]</span></a><span>. Further, redundant information is avoided in the spike structure, using a technique called </span><em><span>wave front</span></em><span> (Long and Fox, 1999), which results in advantageous space requirements over Graphplan.</span></p><p><span>Sensory Graphplan SGP (Weld et al., 1998) is an extension to Graphplan that not only supports conditional effects in the way described in (Gazen and Knoblock, 1997), but also deals with uncertain effects (Smith and Weld, 1998) and uncertainty in the initial situation. The idea presented in (Smith and Weld, 1998) is to extend a separate planning graph for each possible world, keeping track of mutual exclusion across the worlds, and then to search backwards for a plan that works in all possible worlds. SGP introduces observational effects of the form </span><em><span>(sense wwf)</span></em><span>, where </span><em><span>wwf</span></em><span> denotes an arbitrary logical expression composed of propositions. Operators in SGP may have zero or more such observational effects, which, when executed at runtime, deliver the truth value of the specified expression </span><em><span>wwf</span></em><span>. To accomplish this extension of Graphplan, SGP modifies the graph expansion phase, such that it derives knowledge propositions from the sensor definitions and the previous planning-graph proposition layer. In addition, it incorporates a conditioning threat resolution method into the solution extraction phase. Furthermore, SGP generates contingent plans with branches that can rejoin.</span></p><h3><a name="4.3---------partial-order-refinement-planning" class="md-header-anchor"></a><span>4.3         Partial Order Refinement Planning</span></h3><p><span>In contrast to the techniques discussed so far, Partial Order Refinement Planners – also called Partial Order Causal Link Planners (POCL) or Partial Order Planners (POP) – formulate the planning problem not as search through the space of </span><em><span>world states</span></em><span>, but rather as a search in the space of </span><em><span>partiallyspecified plans</span></em><span>, i.e. the nodes of the search space are not states but </span><em><span>plans</span></em><span>, and the arcs between the nodes are not action executions but </span><em><span>plan refinements</span></em><span>.</span></p><p><span>POCL planners usually produce partially ordered plans, i.e. not all actions have a fixed order in the plan, and a plan may have several different linearizations, which all achieve the identical result.</span></p><p><span>A partially ordered plan, in older literature also called task network, can be represented as a quadruple </span><em><span>π</span></em><span> = hS</span><em><span>,</span></em><span>O</span><em><span>,</span></em><span>B</span><em><span>,</span></em><span>Li, which consists of the following components: S is a set of plan steps, i.e. instances of operations. O is a set of ordering constraints. Each ordering constraint is of the form </span><em><span>si</span></em><span> ≺ </span><em><span>sj</span></em><span>, which means that the step </span><em><span>si</span></em><span> must be executed </span><em><span>before</span></em><span> step </span><em><span>sj</span></em><span>. If the set S of some plan </span><em><span>π</span></em><span> has at least two steps </span><em><span>sa</span></em><span> and </span><em><span>sb</span></em><span> where O neither contains </span><em><span>sa</span></em><span> ≺ </span><em><span>sb</span></em><span> nor </span><em><span>sa</span></em><span> ≺ </span><em><span>sb</span></em><span>, then </span><em><span>π</span></em><span> is a </span><em><span>partially ordered</span></em><span> plan. B is a set of variable binding constraints on the parameters of action instances: Each variable constraint is of the form </span><em><span>var</span></em><span> = </span><em><span>x</span></em><span> or </span><em><span>var</span></em><span> 6= </span><em><span>x</span></em><span>, where </span><em><span>var</span></em><span> is a variable of some plan step and </span><em><span>x</span></em><span> is either a constant value or a reference to a variable of some other plan step. If only ground plan steps are used, then B = ∅. L is a set of causal links. Causal links are used to keep track why a step was introduced to a plan and to prevent other steps from interfering with that purpose. If a step </span><em><span>si</span></em><span> achieves a proposition </span><em><span>p</span></em><span> to satisfy a precondition of step </span><em><span>sj</span></em><span>, the causal link </span><em><span>si</span></em><span> →</span><em><span>p sj</span></em><span> is added to L.</span></p><p><span>Further, the following derived sets are considered in partial order planning: OC is the set of open conditions of a plan. An open condition →</span><em><span>p s</span></em><span> emerges when </span><em><span>p</span></em><span> is a literal that is part of </span><em><span>Prec(s)</span></em><span> and when there is no causal link </span><em><span>sx</span></em><span> →</span><em><span>p s</span></em><span> in L. In other words, open conditions are preconditions of plan steps which have not yet been addressed by the current plan. UL is the set of unsafe links. A causal link </span><em><span>si</span></em><span> →</span><em><span>p sj</span></em><span> is called </span><em><span>unsafe</span></em><span> if there exists a step </span><em><span>sk</span></em><span> ∈ S such that (i) ¬</span><em><span>p</span></em><span> is part of the effect of (</span><em><span>sk</span></em><span>) and (ii) O is consistent with {</span><em><span>si</span></em><span> ≺ </span><em><span>sk</span></em><span> ≺ </span><em><span>sj</span></em><span>}. In such a case, </span><em><span>sk</span></em><span> is said to </span><em><span>threaten</span></em><span> the causal link </span><em><span>si</span></em><span> →</span><em><span>p sj</span></em><span>. The union of a plan’s open conditions and unsafe links is called the set F of </span><em><span>flaws</span></em><span> of </span><em><span>π</span></em><span>, i.e. F(</span><em><span>π</span></em><span>) = OC(</span><em><span>π</span></em><span>) ∪ UL(</span><em><span>π</span></em><span>). A plan </span><em><span>π</span></em><span> that has no flaws is called </span><em><span>complete</span></em><span>.</span></p><p><span>An open condition →</span><em><span>p s</span></em><span> can be resolved by introducing or reusing a plan step that has an effect achieving </span><em><span>p</span></em><span>. On the other hand, a </span><em><span>threat</span></em><span> of a causal link</span><img src='file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif' alt='img' referrerPolicy='no-referrer' /><span> by a step </span><em><span>sk</span></em><span> can be possibly resolved either by </span><em><span>promotion</span></em><span>, i.e. by adding an ordering constraint </span><em><span>sk</span></em><span> ≺ </span><em><span>si</span></em><span> to O or by </span><em><span>demotion</span></em><span>, i.e. by adding </span><em><span>sj</span></em><span> ≺ </span><em><span>sk</span></em><span> to O. If the planner uses lifted actions, i.e. if it allows action instances with variables in their parameter lists, a threat can also possibly be resolved by </span><em><span>separation</span></em><span>, that is by adding binding constraints such that </span><em><span>p</span></em><span> and ¬</span><em><span>p</span></em><span> cannot be unified. The way a planner navigates through plan space, i.e. the strategy it employs to chose the plans to refine and the flaws to remove determines the efficiency of the planner.</span></p><p><span>The inception of partially ordered planning in 1975 with NOAH (Sacerdoti, ) sparked research and development activities during nearly three decades. In 1977, the NONLIN system (Tate, 1977) was presented, which introduced the concept of causal links. A formal account of partial order planning was given in (Chapman, 1987), which presented the TWEAK system, which could handle conjunctive and disjunctive preconditions as well as conjunctive effects. (Chapman, 1987) also provides proofs of TWEAKS soundness and completeness, whereby the latter is given using the </span><em><span>modal truth criterion</span></em><span> (MTC) to explicitly check that all the safe ground linearizations correspond to solutions. More recent planners, however, depend on </span><em><span>protection strategies</span></em><span> and </span><em><span>conflict resolution</span></em><span> to indirectly guarantee the safety and necessary correctness of the solution: SNLP (McAllester and Rosenblitt, 1991) introduces the notion of threats and safety conditions, and UCPOP (Penberthy and Weld, 1992) extends the complexity of domain and problem descriptions to actions that have conditional effects and universally quantified preconditions and effects and universally quantified goals. Much work has followed to scale up SNLP and UCPOP, most importantly involving heuristics for efficient flaw selection which was improved in (Peot and Smith, 1993; Williamson and Hanks, 1996; Schubert and Gerevini, 1995; Pollack et al., 1997). Despite those gradual improvements, partial order planning was outperformed by the new Planning Graph-, SAT- and heuristic state space planners which have emerged in the second half of the 1990ies.</span></p><p><span>In recent years (since around 2001) several promising attempts have been carried out to reclaim some of the repudation of POCL planning: in (Nguyen and Kambhampati, 2001) it was noted that the techniques responsible for the efficiency of Graphplan and heuristic state planners can be adapted to dramatically improve the efficiency of partial order planning. (Nguyen and Kambhampati, 2001) introduce RePOP, a POP implementation that incorporates several enhancements: it uses a Planning Graph to compute an estimation of the cost of achieving a set of (sub-) goals. Further, it uses a novel technique of handling unsafe links: An unsafe link</span><img src='file:///C:/Users/lenovo/AppData/Local/Temp/msohtmlclip1/01/clip_image004.gif' alt='img' referrerPolicy='no-referrer' /><span> that is in conflict with an action </span><em><span>ak</span></em><span> is not automatically solved by promotion or demotion, which would result in new partial plans, eventually blowing up the plan space and decreasing performance; instead, RePOP uses </span><em><span>disjunctive constraint handling</span></em><span>, proposed in (Kambhampati and Yang, 1996), which is to resolve the unsafe link by posting a disjunctive ordering constraint that captures the promotion and demotion possibilities, and incrementally simplifies these constraints by propagation techniques, which results in the detection of many failing plans before they get selected for refinement. Further, RePOP improves the consistency enforcement of partial order planning. POP considers the causal link </span><em><span>ai</span></em><span> →</span><em><span>p aj</span></em><span> only threatened by an action </span><em><span>a</span></em><span>, if it has an effect ¬</span><em><span>p</span></em><span>. Often </span><em><span>a</span></em><span> might have an effect </span><em><span>q</span></em><span> such that no legal state can have </span><em><span>p</span></em><span> and </span><em><span>q</span></em><span> true together. In order to detect such implicit conflicts, information about reachable states is required. Again, a Planning Graph is employed to generate this information. The reachable states are then contrasted with pre- and post-</span><em><span>cutsets</span></em><span>, which are unions of pre- and post-conditions derived from the chains of plan steps defined by causal link and ordering constraints. If these cutsets violate the properties of the reachable states, i.e. if a mutex is detected (cf. Sect. 4.2), then the partial plan is discarded. The result of these enhancements is that RePOP is able to demonstrate equal and sometimes better performance than the CSP and state based planners it has borrowed the powerful conflict detection techniques from. At the same time, it is able to generate more compact solutions in many cases and it retained the openness and flexibility of the POP framework, which is considered one of the advantages of that framework (Smith et al., 2000).</span></p><p><span>Another recent advancement of partially ordered planning was achieved by the Versatile Heuristic Partial Order Planner (VHPOP), presented in (Younes and Simmons, 2002; Younes and Simmons, 2003), which competed successfully at the 3rd International Planning Competition IPC-3.</span></p><p><span>Like SNLP and UCPOP, VHPOP uses the </span><em><span>A</span></em><span>∗ algorithm (Hart et al., 1968) to search through the plan space. The </span><em><span>A</span></em><span>∗ algorithm requires a search node evaluation function </span><em><span>f</span></em><span>(</span><em><span>n</span></em><span>) = </span><em><span>g</span></em><span>(</span><em><span>n</span></em><span>) + </span><em><span>h</span></em><span>(</span><em><span>n</span></em><span>), where </span><em><span>g</span></em><span>(</span><em><span>n</span></em><span>) is the cost of getting to </span><em><span>n</span></em><span> from the start node (i.e. the initial plan) and </span><em><span>h</span></em><span>(</span><em><span>n</span></em><span>) is the estimated remaining cost of reaching the goal node (i.e. the complete plan). To encourage search for minimal plans, the cost of a plan is the number of actions in it; while SNLP and UCPOP use the number of open flaws F(</span><em><span>π</span></em><span>) of a plan to give an estimation of </span><em><span>h</span></em><span>(</span><em><span>π</span></em><span>), the VHPOP planner adapts the additive heuristic </span><em><span>hadd</span></em><span> of HSP (cf. Sect. 4.1) to achieve a better informed heuristic, which takes into account positive interactions between goals. Like the state space planner FF, VHPOP utilizes a relaxed Planning Graph to extract the data for </span><em><span>hadd</span></em><span>.</span></p><p><span>While these heuristics inform </span><em><span>plan selection</span></em><span>, VHPOP also provides powerful heuristics for </span><em><span>flaw selection</span></em><span>: Besides implementations of existing strategies such as DUnf and DSep (Peot and Smith, 1993), LCFR (Joslin and Pollack, 1994), and ZLFIO (Schubert and Gerevini, 1995), VHPOP introduces novel flaw selection strategies: </span><em><span>Static-first</span></em><span> deals efficiently with static open conditions, </span><em><span>LCFF-Loc</span></em><span> allows for local flaw selection, which makes the planner less sensitive to precondition order in operator specifications, and several conflict-driven flaw section strategies are introduced which build on the assumption that those open conditions which would be threatened when closed, should be treated with higher priority (Younes and Simmons, 2003).</span></p><p><span>Furthermore, VHPOP extends the POP framework to handle durative actions as specified by PDDL 2.1 level 3, attaching temporal annotations to open conditions which tell the planner at which time step the condition must hold.</span></p><h3><a name="4.4---------planning-as-satisfiability" class="md-header-anchor"></a><span>4.4         Planning as Satisfiability</span></h3><p><span>The idea behind the </span><em><span>planning as satisfiability</span></em><span>-approach is to express the planning problem as a reasoning problem for which powerful problem solving algorithms exist.</span></p><h4><a name="4.4.1--------planning-as-propositional-satisfiability" class="md-header-anchor"></a><span>4.4.1        Planning as Propositional Satisfiability</span></h4><p><span>The logical approach to planning has traditionally been </span><em><span>deduction</span></em><span> (e.g. (Green, 1969; McCarthy and Hayes, 1987; Rosenschein, 1990)), that is, to find a proof that the initial conditions together with the domain axioms (which define the semantics of the operators) and some sequence of actions imply the goal situation (expressed as logical formula). The proof for such a theorem is any valid instantiation of the logical theorem, and the action sequences can be extracted from such an instantiation.</span></p><p><span>However, in (Kautz and Selman, 1992) planning through </span><em><span>satisfiability</span></em><span> checking was presented. In that approach, a planning problem is not a theorem to be proved, instead it is formulated as a set of axioms with the property that </span><em><span>any</span></em><span> model of the axioms correspond to a valid plan. This property is achieved by crafting axioms that rule out unintended (anomalous) models, for instance axioms are needed to explicitly rule out the possibility of executing an action while its precondition is not fulfilled.</span></p><p><span>Further, the axioms do not contain quantification or terms, and all predicates have a trailing argument that takes a time step. For instance[</span><a href='#'><span>6</span><span>]</span></a><span>, in the well known blocks world (Gupta and Nau, 1992), the planning problem of achieving </span><em><span>on</span></em><span>(</span><em><span>B,A</span></em><span>) from an initial situation </span><em><span>on</span></em><span>(</span><em><span>A,B</span></em><span>) ∧ </span><em><span>on</span></em><span>(</span><em><span>B,Table</span></em><span>) would be expressed as:</span></p><p><em><span>on</span></em><span>(</span><em><span>A,B,</span></em><span>1) ∧ </span><em><span>on</span></em><span>(</span><em><span>B,Table,</span></em><span>1) ∧ </span><em><span>clear</span></em><span>(</span><em><span>A,</span></em><span>1) ∧ </span><em><span>on</span></em><span>(</span><em><span>B,A,</span></em><span>3)</span></p><p><span>Further, the semantics (preconditions and effects) of the </span><em><span>move</span></em><span> operator would be formalized as:</span></p><p><span>∀</span><em><span>x,y,z,i.move</span></em><span>(</span><em><span>x,y,z,i</span></em><span>) ⊃ (</span><em><span>clear</span></em><span>(</span><em><span>x,i</span></em><span>) ∧ </span><em><span>clear</span></em><span>(</span><em><span>z,i</span></em><span>) ∧ </span><em><span>on</span></em><span>(</span><em><span>x,y,i</span></em><span>))</span></p><p><span>Additional axioms are needed to make sure that exactly one action is taken at one time step. In this example, the only model that satisfies the axiomatized planning problem is:</span></p><p><span>{</span><em><span>move</span></em><span>(</span><em><span>A,B,Table,</span></em><span>1)</span><em><span>,move</span></em><span>(</span><em><span>B,Table,A,</span></em><span>2)}</span></p><p><span>which is the intended model and which can serve as a plan for an agent. The models can be constructed using satisfiability decision procedures such as the Davis-Putnam procedure or stochastic procedures such as GSAT (Selman et al., 1992); another example is WalkSAT, also called WSAT (Selman et al., 1993).</span></p><p><span>This approach to planning turned out to be highly competitive (Kautz and Selman, 1996). Planning procedures based on this techniques are Satplan (Kautz and Selman, 1992) and the successor Blackbox (Kautz and Selman, 1998a) which combines Satplan with ideas from Graphplan. Both systems competed well in the international planning competitions.</span></p><p><span>A similar approach is taken by the LGP system (Gerevini and Serina, 2002) and its successor LGP-td (Gerevini et al., 2004). Both are based on WalkSAT, but incorporate a best-first search algorithm and use a Planning Graph for search heuristics.</span></p><p><span>Beside the good performance, SAT based planning has another advantage: since states are modeled explicitly in this framework (the trailing arguments of the atoms), it is easy to formulate requirements on states, as discussed in (Huang et al., 1999; Kautz and Selman, 1998b). This, in turn is useful for expressing the complex goals discussed in Sect. 3.3.</span></p><h4><a name="4.4.2--------planning-as-description-logic-satisfiability" class="md-header-anchor"></a><span>4.4.2        Planning as Description Logic Satisfiability</span></h4><p><span>Another approach that presents the planning task as a logical satisfiability problem is presented in (Berardi et al., 2003). More precisely, the article concentrates on the problem of automatic Web service composition. In this approach the “target logic” is not Propositional Logic, but the Description Logic ALU.</span></p><p><span>The approach defines a </span><em><span>community</span></em><span> of Web services, which is characterized by a common set of actions, called the alphabet of the community and a set of Web services specified in terms of the common set of actions. The interaction protocols a service offers are expressed as </span><em><span>execution trees</span></em><span>, where each node represents a possible state in the client-server interplay and each edge represents an action invoked by the client following the protocol. The Web service composition problem is now to identify an execution tree composed of the actions of the services in the community, that corresponds with a given desired execution tree.</span></p><p><span>The task of constructing such a tree is reminiscent of the task of producing a model of a description logic concept to prove its satisfiability (or its unsatisfiability): to exploit this property, the Web service domain and planning problem are transformed from a situation calculus representation to ALU, and then any of the highly efficient tableau-based Description Logic reasoners (such as (Volker Haarslev, 2001; Horrocks, 1999)) can be used to generate the tree model of the satisfiability check, from which the synthesized process (if it exists) can be directly extracted.</span></p><h4><a name="4.4.3--------planning-as-petri-net-reachability" class="md-header-anchor"></a><span>4.4.3        Planning as Petri-Net Reachability</span></h4><p><span>Another work that starts with a situation calculus based axiomatization of the planning problem and then transforms it to fit into a well-known formal framework was presented in (Narayanan and McIlraith, 2002): This article suggests that Web service planning tasks can be carried out under the notion of </span><em><span>reachability analysis</span></em><span> of Petri nets (Petri, 1962). The idea is to create a Petri net based on atomic Web services that represents all possible combinations of atomic operations and to specify the desired goal as a state of this Petri net (i.e. as a configuration of tokens). Standard Petri net techniques, among them satisfiability checking, can then be used to determine if this goal state is reachable. These techniques can also be used to validate whether a plan is well-formed (Narayanan and McIlraith, 2002).</span></p><h3><a name="4.5---------planning-as-logic-programming" class="md-header-anchor"></a><span>4.5         Planning as Logic Programming</span></h3><p><span>Another approach that proposes a way to encode the action laws of a planning domain as a logical representation that is amendable to formal reasoning methods is the Planning as </span><em><span>Logic Programming</span></em><span> approach.</span></p><p><span>A Logic program is composed by a set of Horn clauses of the form </span><em><span>A</span></em><span> ← </span><em><span>B</span></em><span>1</span><em><span>,...,Bn</span></em><span>. Each such Horn clause can also be interpreted as a disjunction of literals with at most one positive literal, i.e. </span><em><span>A</span></em><span>∨¬</span><em><span>B</span></em><span>1 ∨</span><em><span>...</span></em><span>∨¬</span><em><span>Bn</span></em><span>. Negativity in Logic programs is usually expressed as </span><em><span>negation-as-failure</span></em><span> (NAF), which makes them nonmonotonic.</span></p><p><span>The relation between logic programming (LP) and planning, as well as the encoding of planning problems as Logic programs is extensively studied in the literature, e.g. in (Gelfond and Lifschitz, 1993; Turner, 1997; Lifschitz, 1999).</span></p><p><span>While the direct application of deductive reasoning, such as Prolog’s SLD would appear self-evident, much of the progress of the Planning as LP-approach has been achieved using alternative methods, inspired by (Subrahmanian and Zaniolo, 1995). (Subrahmanian and Zaniolo, 1995) show that planning problems can be converted to Logic programs in linear time such that a given goal </span><em><span>G</span></em><span> is achievable in the planning domain if and only if a related goal </span><em><span>G</span></em><span>∗ is true in some </span><em><span>stable model</span></em><span> of the logic program obtained by the transformation; the goal </span><em><span>G</span></em><span>∗ can be obtained in linear time as well (Subrahmanian and Zaniolo, 1995). These stable models can be efficiently generated by computing the </span><em><span>answer sets</span></em><span> of the logic program, as implemented in tools like SMODELS (Niemelae and Simons, 1997). (Dimopoulos et al., 1997) report empirical tests of this approach, and suggest that, given a proper encoding of the Logic programs, the performance can keep up with the performance of general-purpose planning algorithms such as Graphplan or Satplan.</span></p><p><span>Other applications of Logic programming have been Reiter’s implementation of Golog and regression for situation calculus (Reiter, 2001). Also mentioned should be (Shanahan, 2000) which presents a Logic programming encoding of the event calculus. In the realm of Web service composition, the SWORD toolkit was presented in (Ponnekanti and Fox, 2002), which uses Prolog to reason about information providing services, whereby plans are extracted directly from the execution trace of the Prolog interpreter.</span></p><h2><a name="5-----------planning-with-control-knowledge" class="md-header-anchor"></a><span>5           Planning with Control Knowledge</span></h2><p><span>Although the performance of many of the planners described in the last sections is quite impressive, there is a belief among many researchers, that it is necessary to provide the planing agent with domain- or task dependent control knowledge in order to achieve good performance in real world domains.</span></p><p><span>In the following sections, we will briefly review planning techniques that allow to incorporate and exploit domain or task-dependent control knowledge in one way or the other.</span></p><h3><a name="5.1---------hierarchical-task-network-planning" class="md-header-anchor"></a><span>5.1         Hierarchical Task Network Planning</span></h3><p><span>Hierarchical Task Network (HTN) planning was first introduced in the early Abstrips (Sacerdoti, 1973) planning system, followed by NOAH and several other planners; it was given a formal semantics in (Erol et al., 1994b; Erol et al., 1994a).</span></p><p><span>HTN planning provides hierarchical abstraction, a powerful strategy to deal with the complexity of large and complicated real world planning domains. Like other planning paradigms, HTN planning assumes a set of operators that achieve certain defined effects when its preconditions hold directly before its execution. However, in addition to operations (which are called </span><em><span>primitive tasks</span></em><span> in HTN planning), HTN planning also supports a set of </span><em><span>methods</span></em><span>, where each is a prescription for how to decompose some task into some set of subtasks. Such method descriptions represent common </span><em><span>domain knowledge</span></em><span>, or if viewed from the planner’s perspective, represent </span><em><span>plan fragments</span></em><span>.</span></p><p><span>According to the definition in (Erol et al., 1994b), there are three types of goals in HTN planning: (i) goal tasks, which are desired properties of the final state, just like in most other planning paradigms, (ii) the already mentioned primitive tasks, and (iii) compound tasks that denote desired changes that involve several goal tasks and primitive tasks.</span></p><p><span>A variant of HTN planning which received much attention recently is </span><em><span>ordered task decomposition</span></em><span> planning, where the agent plans for tasks in the same order that they will be executed, which reduces the complexity of the planning problem greatly. Planners based on that principle, like SHOP (Simple Hierarchical Ordered Planner) (Nau et al., 1999) accept goals as task lists, where compound tasks may consist of compound tasks or primitive tasks; goal tasks are not supported. Hence, ordered task decomposition system do not plan to achieve a defined (declarative) goal, but rather to carry out a given (complex or primitive) task.</span></p><p><span>Such a HTN based planning system decomposes the desired task into a set of sub-tasks, and these tasks into another set of sub-tasks (and so forth), until the resulting set of tasks consists only of primitive tasks, which can be executed directly by invoking atomic operations. During each round of task decomposition, it is tested whether certain given conditions are violated. The planning problem is successfully solved if the desired complex task is decomposed into a set of primitive tasks without violating any of the given conditions.</span></p><p><span>An approach of using HTN planning in the realm of Web Services was proposed in (Hendler et al., 2003), facilitating the SHOP2 system (Nau et al., 2003), which belongs to the family of </span><em><span>ordered task decomposition</span></em><span> planners we described above. The papers (Hendler et al., 2003; Wu et al., 2003) present a transformation method of OWL-S processes into a hierarchical task network. OWL-S processes are, like HTN task networks, pre-defined descriptions of actions to be carried out to get a certain task done, which makes the transformation rather natural. The advantage of the approach is its ability to deal with very large problem domains; however, the need to explicitly provide the planner with a task it needs to accomplish may be seen as a disadvantage, since this requires descriptions that may not always be available in dynamic environments.</span></p><h3><a name="5.2---------high-level-program-execution" class="md-header-anchor"></a><span>5.2         High-level Program Execution</span></h3><p><span>In the classical approaches to planning, a plan is synthesized given a domain description and a planning goal, where the planner has to search a – usually very large – space of possibilities to identify a proper solution to the planning problem. An alternative approach is </span><em><span>high-level program execution</span></em><span>; the idea behind this approach is that, instead of searching for a sequence of actions that satisfies some declarative goal, the task is to identify a sequence of actions which constitutes a </span><em><span>legal execution</span></em><span> of a given high level program. As in planning, it is necessary to reason about the preconditions and effects of the domain’s operators to find out which actions can be applied in detail. If the high level program is formulated in detail and is formulated deterministically, then not much reasoning is left to be carried out; otherwise, when the programm is formulated not in detail and if it makes use of nondeterministic control constructs, then the search task begins to resemble traditional planning (Giacomo et al., 2000).</span></p><p><span>The Golog (alGOL in LOGic) (Levesque et al., 1997) language is such a high-level programming language, and it is particularly designed for the specification and execution of complex actions in dynamic domains. Further, it is logic-based, which means that Golog program are amendable to formal verification procedures and Golog based planning problems can be carried out by logic tools such as theorem provers.</span></p><p><span>Golog is based on the situation calculus (cf. Sect. 3.1), which was introduced by (McCarthy, 1963) and since then is often used as a means for providing a formal account of dynamic systems. While early treatments of the situation calculus identify situations with states, i.e. a description of the universe at an instant of time (McCarthy and Hayes, 1969), more recent formal treatment (Levesque et al., 1998; Pirri and Reiter, 1999) of the situation calculus identifies situations with world histories. All changes to the world are results of named actions. A situation is a possible world history, resulting from a sequence of actions, and it is expressed as a first order term. The constant </span><em><span>S</span></em><span>0 denotes the </span><em><span>initial situation</span></em><span>, i.e. the empty sequence of actions. The function </span><em><span>do</span></em><span>(</span><em><span>α,s</span></em><span>) denotes the situation that results from executing action </span><em><span>α</span></em><span> in situation </span><em><span>s</span></em><span>. Actions are written as functions and may be parameterized. For example, the function </span><em><span>paint</span></em><span>(?</span><em><span>o,</span></em><span>?</span><em><span>c</span></em><span>) might stand for painting an object ?</span><em><span>o</span></em><span> with color ?</span><em><span>c</span></em><span>, in which case </span><em><span>do</span></em><span>(</span><em><span>paint</span></em><span>(</span><em><span>Door,Red</span></em><span>)</span><em><span>,s</span></em><span>) would denote the situation resulting from painting the </span><em><span>Door</span></em><span> with red color. The expression </span><em><span>do</span></em><span>(</span><em><span>putDown</span></em><span>(</span><em><span>Red</span></em><span>)</span><em><span>,do</span></em><span>(</span><em><span>paint</span></em><span>(</span><em><span>Door,Red</span></em><span>)</span><em><span>,do</span></em><span>(</span><em><span>pickUp</span></em><span>(</span><em><span>Red</span></em><span>)</span><em><span>,S</span></em><span>0))) denotes the situation resulting from executing </span><em><span>pickUp(Red)</span></em><span> in situation </span><em><span>S</span></em><span>0, then executing </span><em><span>paint(Door, Red)</span></em><span>, followed by </span><em><span>putDown(Red)</span></em><span>.</span></p><p><span>Golog builds on top of the situation calculus by providing a set of extralogical constructs which serve as </span><em><span>abbreviations</span></em><span> for logical expressions in the language of the situation calculus. The abbreviation </span><em><span>Do</span></em><span>(</span><em><span>δ,s,s</span></em><span>0), </span><em><span>macroexpands</span></em><span> into a situation calculus formula that says that it is possible to reach situation </span><em><span>s</span></em><span>0 from situation </span><em><span>s</span></em><span> by executing a sequence of actions as specified by </span><em><span>δ</span></em><span>, which is a complex action expression. Golog provides the following macro-expandable language constructs: primitive actions, test actions, sequence, nondeterministic choice of two actions, nondeterministic choice of action arguments and nondeterministic iteration (while loops). Golog also allows for the definition of (possibly recursive) procedures (Reiter, 2001).</span></p><p><span>Given a situation calculus-based domain axiomatization </span><em><span>Axioms</span></em><span>, an initial situation </span><em><span>S</span></em><span>0 and a Golog program </span><em><span>δ</span></em><span>, the planning (i.e. program execution) task can be expressed as the following theorem proving task (Reiter, 2001):</span></p><p><em><span>Axioms</span></em><span> ` (∃</span><em><span>s</span></em><span>)</span><em><span>Do</span></em><span>(</span><em><span>δ,S</span></em><span>0</span><em><span>,s</span></em><span>)</span></p><p><span>In other words, the planner has to identify a situation </span><em><span>s</span></em><span> for which the macroexpansion is provable from the axioms. The instance of </span><em><span>s</span></em><span> is obtained as a side effect of the proof, and from this instance a sequence of actions </span><em><span>~a</span></em><span> can be extracted such that </span><em><span>Axioms</span></em><span> |= </span><em><span>Do</span></em><span>(</span><em><span>δ,S</span></em><span>0</span><em><span>,do</span></em><span>(</span><em><span>~a,s</span></em><span>)) holds, where </span><em><span>~a</span></em><span> abbreviates </span><em><span>do</span></em><span>(</span><em><span>an,do</span></em><span>(</span><em><span>an</span></em><span>−1</span><em><span>,...,do</span></em><span>(</span><em><span>a</span></em><span>1</span><em><span>,S</span></em><span>0))). A Prolog-based implementation of a Golog interpreter is presented in (Levesque et al., 1997).</span></p><p><span>A variant of Golog capable of dealing with concurrency is ConGolog (Concurrent Golog) (Giacomo et al., 2000): it allows concurrent processes, whereby the concurrency is established by interleaving the atomic actions in the component processes; it also supports interrupts (e.g. to handle the situation when an alarm button is hit in an elevator) and exogenous actions, i.e. actions that may occur in parallel to the program but are not under control of the interpreter. A Prolog-based interpreter for ConGolog is presented in (Giacomo et al., 2000).</span></p><p><span>In (McIlraith and Son, 2001; McIlraith and Son, 2002) a modified version of ConGolog is applied to the problem of Web Service composition. The ConGolog interpreter is extended with the ability to include customized user constraints, a more flexible variant of Golog’s sequence construct and the ability to implement sensing actions as external function calls. In (Narayanan and McIlraith, 2002), a formal tranformation from OWL-S to situation calculus and Golog is given. In this context, OWL-S processes can serve as specification of desired processes to be carried out as well as a description of the atomic and complex actions offerered by Web services. The Web service composition problem would then be to find an execution of a Golog program that does satisfy the properties defined in the goal.</span></p><h3><a name="5.3---------planning-as-model-checking" class="md-header-anchor"></a><span>5.3         Planning As Model Checking</span></h3><p><span>The planning as model checking approach was first proposed in (Cimatti et al., 1997; Giunchiglia and Traverso, 1999), which formulates the planning problem as semantic model checking problem. Model checking is a formal verification technique, which allows to determine whether a property holds in a certain system formalized as a finite state model. This technique is used for the verification of hardware and software systems, to achieve a formal account of the system’s behavior, e.g. that a system does never reach a certain unwanted state (safety), or that it is guaranteed to reach a certain state at some point (liveness). For example, the SPIN model-checker was used to verify the multi-threaded plan execution module in NASA’s DEEP SPACE 1 mission and discovered five previously unknown concurrency errors (Havelund et al., 2001). A more general, detailed discussion of model checking for reasoning over systems can be found in (Halpern and Vardi,</span></p><p><span>1991).</span></p><p><span>Planning by model checking (PBM) is semantically well founded and is capable of dealing with nondeterminism, partial observability and extended goals. In PBM, the planning domain is formalized as a nondeterministic state-transition system, where an action is a transition that may bring the system from one state to a set of possible successor states. As in other planning approaches, planning goals may be expressed as constraints about a desired goal state; additionally, goals may be extended by statements about properties about the </span><em><span>plan itself</span></em><span>, e.g. by CTL (Computation Tree Logic) temporal formulas (Emerson, 1990) or using the recently proposed Eagle (Lago et al., 2002) language.</span></p><p><span>The underlying idea of the PBM approach is to generate plans by determining whether the goal formula is true in a model, whereby the model is usually formalized as a Kripke structure. The plans that are generated by PBM are “situated plans” (Georgeff and Lansky, 1990), which are plans that are executed by a reactive agent, which, at each iteration cycle determines the state in which it is situated in, and then applies the action that is foreseen for that state by the plan. To illustrate this more formally, consider a planning domain Σ = (</span><em><span>S,A,γ</span></em><span>), where </span><em><span>S</span></em><span> is a finite set of states, </span><em><span>A</span></em><span> is a finite set of actions and </span><em><span>γ</span></em><span> : </span><em><span>S</span></em><span> × </span><em><span>A</span></em><span> → 2</span><em><span>s</span></em><span> is the nondeterministic state transition function. Now, a valid PBM-generated plan </span><em><span>π</span></em><span>, also called </span><em><span>policy</span></em><span> for this planning domain Σ, is a set of pairs (</span><em><span>s,a</span></em><span>) such that </span><em><span>s</span></em><span> ∈ </span><em><span>S</span></em><span> and </span><em><span>a</span></em><span> ∈ </span><em><span>A</span></em><span>(</span><em><span>s</span></em><span>). It is required that for any state </span><em><span>s</span></em><span> there is (at most) one action </span><em><span>a</span></em><span> such that (</span><em><span>s,a</span></em><span>) ∈ </span><em><span>π</span></em><span>.</span></p><p><span>Due to the nondeterminism allowed in PBM domains, the definition of a solution differs from the definition of a solution under classical planning assumptions. Depending on the contingency inherent in a solution, it may be either </span><em><span>weak</span></em><span>, </span><em><span>strong</span></em><span> or </span><em><span>strong cyclic</span></em><span>: A weak solution is a solution that may achieve the goal but does not guarantee to do so. A strong solution is guaranteed to achieve the goal regardless of the nondeterministic nature of the domain. A strong cyclic solution is one which guarantees to achieve the goal, if </span><em><span>fairness assumptions</span></em><span> are granted which state that the loops the solution foresees will eventually terminate (Giunchiglia and Traverso, 1999).</span></p><p><span>Analogously, several algorithms have been proposed, capable of either constructing weak (e.g. (Cimatti et al., 1997)), strong (e.g. (Daniele et al., 2000)) or strong cyclic (e.g. (Cimatti et al., 1998)) solutions. These algorithms have in common that they always terminate.</span></p><p><span>Since real-world problems involve models that may contain very large numbers of states, practical implementations of these algorithm usually resort to </span><em><span>Symbolic Model Checking</span></em><span> (Burch et al., 1990). In Symbolic Model Checking the sets of possible states of a Kripke-structure and the transition relations between states are represented </span><em><span>symbolically</span></em><span>, usually using vectors of variables that represent the truth value of propositions in states, allowing for more concise, less redundant representation of states and for efficient application of set-theoretic and logical operations. Planning is performed by searching through sets of states, rather then individual states, and the plans themselves are represented as formulas. The practical implementation of the representation and the reasoning techniques of Symbolic Model Checking is often carried out using Binary Decision Diagrams (BDDs) (Bryant, 1986).</span></p><p><span>One implementation of the Planning for Model Checking approach is MIPS (Edelkamp and Helmert, 2000), which is based on BDDs. The main strength of MIPS is its precompilation phase, which identifies implicit domain knowledge, e.g. state invariants, which, when properly encoded can lead to a reduction of the state description length. Further, MIPS implements numerous novel techniques to increase the efficiency of BDD traversal (Edelkamp and Helmert, 2000).</span></p><p><span>Other PBM implementations for deterministic domains are Proplan (Fourman, 2000) and BDDPlan (H¨olldobler and St¨orr, 2000); however, these lack a MIPS-like pre-compilation phase and therefore do not reach the high performance of MIPS in larger domains.</span></p><p><span>While MIPS, Proplan and BDDPLan are designed for </span><em><span>deterministic</span></em><span> domains, systems like MBP (Model Based Planner) (Bertoli et al., 2001) and UMOP (Universal Multi-agent Obdd-based Planner) (Jensen and Veloso, 2000) have been designed to leverage a key advantage of model checking, which is to deal with </span><em><span>nondeterministic</span></em><span> environments: MBP can deal with uncertainty on the initial situation, on the action effects and on the state in which the actions are executed. It uses its own action description language NuPDDL, a variant of PDDL 2.1 which can express uncertainty in the initial state, nondeterministic action effects and non-perfect sensing actions.</span></p><p><span>Similarly, UMOP uses its own domain description language NADL (Nondeterministic Agent Domain Language); NADL problem and domain specifications are translated into symbolic Kripke structures, represented by OBDDs (Bryant, 1986).</span></p><h3><a name="5.4---------temporal-planning" class="md-header-anchor"></a><span>5.4         Temporal Planning</span></h3><p><span>The term “temporal planning” does not necessarily refer to a particular planning technique in the narrow sense, it rather refers to the ability of planners to deal with </span><em><span>temporal aspects</span></em><span> of planning domains and problems. Most planning paradigms have been extended in some way to support some temporal aspects of planning. Examples of such temporal aspects are:</span></p><p><span>•    Durative actions: In classical planning approaches actions are usually formalized as having no temporal extension. However, in many domains, the duration of actions play a role. As a consequence the exact timing of effects and time efficient plans are of interest to the planner.</span></p><p><span>•    Validity intervals of propositions: in classical planning, a proposition remains unchanged until it is explicitly changed by the agent using an operator. In the real world, many fluents are dependent on time; for instance the permission to access a Web service may be valid only during a defined temporal interval.</span></p><p><span>•    Concurrent actions: classical planning usually assumes that only one action is executed at once. POP and its partially ordered plans appear like an exception, but it is not that the temporal concurrency of actions in such plans is deliberatively sought; it just means that these actions are independent and that no constraints excluding their concurrency have been identified. Some problems, however, </span><em><span>require</span></em><span> that two actions must be executed at the same time because a sequential operation would not yield the desired result.</span></p><p><span>•    Specification of temporally extended goals (Bacchus and Kabanza, 1996), which do not only express classical goals of achieving some final state, but also express a set of acceptable </span><em><span>sequences of states</span></em><span>. Temporally extended goals may also extend temporal deadlines, safety and maintenance goals (Weld and Etzioni, 1994; Penberthy and Weld, 1992).</span></p><p><span>The problem of </span><em><span>durative actions</span></em><span> was already addressed by early planners such as the partial order planner NONLIN (Tate, 1977) and the hierarchical SIPE (Wilkins, 1988) planner and is also addressed by more recent planners like VHPOP(Younes and Simmons, 2003), LPG (Gerevini and Serina, 2002) and MIPS (Edelkamp and Helmert, 2000).</span></p><p><em><span>Temporally extended goals</span></em><span> have been addressed by the TLPlan (Bacchus and Kabanza, 1995; Bacchus and Ady, 2001) system, which supports goals specified in an extended version of the Metric Interval Temporal Logic (MITL) (Alur et al., 1996). TLPlan is based on a forward-chaining planning engine. Usually, forward-chaining planners (or state-space planners in general) evaluate the contribution a state makes towards the desired goal by determining its heuristic value (cf. Sect. 4.1). TPLan takes a different approach. It treats each state as a database which it checks against an inverse formulation of the goal formula, and it prunes each state that satisfies such a formula, because this means that it violates a property of the desired goal. It should be noted that the notion of a temporally extended goal formula can be extended to the notion of </span><em><span>domain control knowledge</span></em><span>, which encodes hints to the planners by specifying desired or undesired properties of the states it is supposed to identify.</span></p><p><span>A successor of TLPlan is TALPlanner (Kvarnstrom and Haslum, 2001), which is, like TLPlan, based on forward search, but uses the TAL language instead of MITL to specify the planning goals and domain control knowledge. TAL is a narrative-based linear metric time logic used for reasoning about action and change in incompletely specified dynamic environments. A TAL goal (or control) formula is input to TALplanner which then generates a solution that entails the goal (or control) formulas.</span></p><h2><a name="6-discussion-and-outlook" class="md-header-anchor"></a><span>6 Discussion and Outlook</span></h2><p><span>We will now review the most important requirements we previously discussed and we will contrast them with a selection of state-of-the art planning systems. The core requirements we identified for our problem scenarios (cf. Sect. 2) are:</span></p><p><span>\1.    The </span><em><span>domain complexity</span></em><span> should support a significant subset of ADL: for instance, universally quantified effects are needed to describe web services that deal with multiple objects (e.g. an operation that removes all items from a virtual shopping cart). Explicit markup of sensing actions and nondeterministic service results is desirable as well.</span></p><p><span>\2.    Support for </span><em><span>complex goals</span></em><span> (cf. Sect. 3.3), i.e. “hints” that tell the planner which actions should precede which other actions. This is needed for almost all complex problems, for instance in comparison shopping, where the solution is a sequence of three distinct phases (getting price quotes, making a decision, carrying out the purchase).</span></p><p><span>\3.    As already mentioned, the ability to deal with </span><em><span>incomplete information</span></em><span> (cf. Sect. 3.2), for instance to query catalogs in the Web shopping domain, is a core requirement for most Web service domains. This, in turn calls for support of </span><em><span>sensing</span></em><span> actions which help the agent to acquire the needed data (e.g. a method that returns a list of products an online retailer sells)</span></p><p><span>\4.    Related to the problem of supporting sensing actions is the ability of planners to </span><em><span>dynamically add (or remove) objects</span></em><span> to (or from) the domain, for instance to add knowledge about product information queried from a sensing action, or to properly model a file copy function in the document handling domain.</span></p><p><span>\5.    Finally, there is a strong need for dealing with the </span><em><span>nondeterministic behavior</span></em><span> of services: Web service operations may fail during execution time or they may yield unexpected or undesired results; for instance, an airline in the traveling domain may suddenly run out of free seats (possibly violated the IRP assumption), or an image conversion operation in the e-mail replication scenario may fail.</span>
<span> </span></p><p><span>In the Tables 1 and 2 we contrast a collection of representative planner implementations against our collection of core requirements for WSC problems. The planners listed in Tab. 1 are neoclassical[</span><a href='#'><span>7</span><span>]</span></a><span> planners based on the techniques we discussed in Sect. 4, and the tools listed in Tab. 2 are implementations of the planning with control knowledge approach discussed in Sect. 5.</span></p><p><span>Table 1 shows that most of the neoclassical planners we listed allow for domain descriptions of the necessary complexity, i.e. a significant subset of ADL. However, with the exception of SGP, which provides support for incomplete initial states and sensing operations, the rest of the WSC requirements is not supported by any of these planners.</span></p><p><span>On the other hand, the planners using domain control knowledge offer a much broader support for our requirements: They support complex domains and they allow complex goals as well. For instance, MBP allows to define temporally extended goals and Golog represent goals in a program-like fashion, including branching and iteration. Consequently, nondeterministic domains can be addressed by providing contingency-handling code (e.g. nondeterministic iteration which forces the planner to continue a loop unit the desired effect of some operation is achieved).</span></p><p><span>Does this mean that the WSC problem is already solved by planners with control knowledge and that neoclassical planners can not be used for the task?</span></p><p><span>We think this is not the case: While it is apparent that domain knowledge is a key to solving the WSC problem, it is not clear </span><em><span>which</span></em><span> form of domain knowledge is best suited and </span><em><span>how</span></em><span> it should be gathered and encoded. Here, “soft requirements” like the acceptance of the targeted developer communities are relevant as well. The idea of transforming pre-existing process descriptions (in OWL-S) to domain control information (HTN methods) as exercised by (Hendler et al., 2003) seems a reasonable approach: it does not require the developers to adopt a new logic-based language, but allows them to use wide spread process engineering skills. However, (Hendler et al., 2003) use a restricted variant of HTN planning, i.e. ordered task decomposition planning, which does not support declarative goal tasks. This means that the agent solely depends on the task lists it is given and that is does not attempt to find “creative” solutions on its own. Similarly, sensing actions are not called because the </span><em><span>agent</span></em><span> identifies the need for sensing; instead the sensing action is explicitly predefined in the task list. While this is a useful and pragmatic approach for many domains, we think it would still be interesting to look for alternative approaches that allow for more flexibility on the agent’s part, for instance to deal with situations where no predefined strategies exist yet.</span></p><p><span>Furthermore, the domain-independent neoclassical planners of Tab. 1 are far from being inapplicable to the WSC problem. What is required, however, is a proper architecture that allows for the decomposition of the planning problem into a set of subproblems that match the capabilities of the neoclassical planners.</span></p><p><span>An example would be an execution monitoring &amp; replanning architecture (e.g. (Haigh, 1998)), where a controller component transforms the problem into a sequence of simpler planning problems and uses the feedback from plan execution to better inform the heuristics of the embedded planner(s). Since the planning problem is split up into a sequence of planning problems, the problem of dynamic object creation and destruction disappears (because the world is re-created at each step) and even the planning for sensing actions becomes possible for classical planners, as informally described in (Peer, 2004a).</span></p><p><span>Finally, there is a number of unaddressed issues, which, once solved, may turn out to be very helpful regardless of the planning approach taken. One central issue is </span><em><span>automatic domain analysis</span></em><span>; in this survey we discussed several planning implementations which outperformed their direct competition because of </span><em><span>automatically generated</span></em><span> domain knowledge gathered during a preprocessing phase (e.g. STAN, MIPS). Therefore, it appears to be a worthwhile undertaking to identify ways of gathering useful control knowledge from Web service domains. Similarly, the application of </span><em><span>learning techniques</span></em><span> (e.g. based on feedback from earlier runs) may be considered to improve the agent’s planning heuristics.</span></p><p><strong><span>Acknowledgements</span></strong></p><p><span>This work has been supported by the European Commission and by the Swiss Federal Office for Education and Science within the 6th Framework Programme project REWERSE number 506779 and by the Swiss National Science Foundation under contract 200021-104009. The author would like to thank Juergen Zimmer, Drew McDermott and Maja Vukovic for their comments and valuable feedback.</span></p><p><span> </span></p></div>
</body>
</html>